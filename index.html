<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Minjoon Jung</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<tr style="padding:0px">
    <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center">
                    <name>Minjoon Jung</name>
                </p>
                <p>I am a Ph.D. candidate in <a href="https://gsai.snu.ac.kr/">Graduate School of AI</a> of <a href="https://en.snu.ac.kr/">Seoul National University</a>,
                    advised by <a href="https://bi.snu.ac.kr/~btzhang/">Prof. Byoung-Tak Zhang</a>.
                    Currently, I'm working as a research intern at <a href="https://cvml.comp.nus.edu.sg/">NUS@CVML</a> with <a href="https://doc-doc.github.io/cv/">Dr. Junbin Xiao</a> and <a href="https://www.comp.nus.edu.sg/cs/people/ayao/">Prof. Angela Yao</a>.
                    My research interests include multimodal learning (vision-and-language) and video understanding.
                    If you are interested in collaborating, please feel free to contact me via email.
                    Before to joining Ph.D program, I earned my Bachelor's degree in Software Engineering from <a href="https://www.cau.ac.kr/index.do">Chung-Ang University</a>.
                </p>
                <p>
                    <!--                Before to joining Ph.D program, I earned my Bachelor's degree in Software Engineering from <a href="https://www.cau.ac.kr/index.do">Chung-Ang University</a>.-->
                    <!--                My primary-->
                    <!--                At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.-->
                </p>
                <p style="text-align:center">
                    <a href="mailto:mjjung@bi.snu.ac.kr">Email</a> &nbsp/&nbsp
                    <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                    <a href="https://scholar.google.co.kr/citations?user=YORj6_YAAAAJ&hl">Google Scholar</a> &nbsp/&nbsp
                    <a href="https://github.com/minjoong507/">Github</a> &nbsp
                    <!--                <a href="https://instagram.com/mjjxxng_?igshid=OGQ5ZDc2ODk2ZA==">Instagram</a>-->
                </p>
            </td>
            <td style="padding:2.5%;width:20%;max-width:20%">
                <!--              <a href="images/profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>-->
                <a href="images/new_pic.jpg"><img style="width:150%;max-width:150%" alt="profile photo" src="images/new_pic.jpg" class="hoverZoomLink"></a>
            </td>
        </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Research</heading>
                <p>
                    I have a broad interest in <span class="highlight">vision-and-language</span> and <span class="highlight">video modeling</span>.
                    Recently, I have been researching methods for Large Language Models (LLMs) to understand videos and effectively represent temporal information.
                </p>
            </td>
        </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
        <!--            <tr>-->
        <!--            <td style="padding:20px;width:100%;vertical-align:middle">-->
        <!--              <heading>Research</heading>-->
        <!--              <p>-->
        <!--                I have a broad interest in <span class="highlight">vision-and-language</span> and <span class="highlight">video modeling</span>.-->
        <!--                  Recently, I'm focusing on video understanding tasks, such as video moment retrieval.-->
        <!--&lt;!&ndash;                  My primary research interests are <span class="highlight">multimodal learning</span>, <span class="highlight">video-and-language</span> and <span class="highlight">video understanding tasks</span>.&ndash;&gt;-->
        <!--&lt;!&ndash;                Representative papers are <span class="highlight">highlighted</span>.&ndash;&gt;-->
        <!--              </p>-->
        <!--            </td>-->
        <!--          </tr>-->
        <!--        </tbody></table>-->
        <!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->

        <tr onmouseout="bakedsdf_stop()" onmouseover="bakedsdf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <heading>Publications</heading>
                <p></p>
                <div class="one">
                    <!--          <div class="two" id='eclipse_image'><video  width=100% height=100% muted autoplay loop>-->
                    <!--          <source src="images/eclipse_after.mp4" type="video/mp4">-->
                    <!--          Your browser does not support the video tag.-->
                    <!--          </video></div>-->
                    <img src='images/BM-DETR.png' width="160" height="130">
                </div>
                <script type="text/javascript">
                    function bakedsdf_start() {
                        document.getElementById('bakedsdf_image').style.opacity = "1";
                    }

                    function bakedsdf_stop() {
                        document.getElementById('bakedsdf_image').style.opacity = "0";
                    }
                    bakedsdf_stop()
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Background-aware Moment Detection for Video Moment Retrieval</papertitle>
                <br>
                <strong>Minjoon Jung</strong>,
                Youwon Jang,
                Seongho Choi,
                Joochan Kim,
                <a href="http://wityworks.com/">Jin-Hwa Kim*</a>,
                <a href="https://bi.snu.ac.kr/~btzhang/">Byoung-Tak Zhang*</a>
                <br>
                <em>Winter Conference on Applications of Computer Vision (WACV)</em>, 2025
                <br>
                <a href="https://arxiv.org/abs/2306.02728">paper</a> /
                <a href="https://github.com/minjoong507/BM-DETR">code</a>
                <p></p>
                <p>
                </p>
            </td>
        </tr>



        <tr onmouseout="bakedsdf_stop()" onmouseover="bakedsdf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
<!--                <heading>Publications</heading>-->
                <p></p>
                <div class="one">
                    <!--          <div class="two" id='bakedsdf_image'><video  width=100% height=100% muted autoplay loop>-->
                    <!--          <source src="images/bakedsdf_after.mp4" type="video/mp4">-->
                    <!--          Your browser does not support the video tag.-->
                    <!--          </video></div>-->
                    <img src='images/PGA.png' width="160", height="130">
                </div>
                <script type="text/javascript">
                    function bakedsdf_start() {
                        document.getElementById('bakedsdf_image').style.opacity = "1";
                    }

                    function bakedsdf_stop() {
                        document.getElementById('bakedsdf_image').style.opacity = "0";
                    }
                    bakedsdf_stop()
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>PGA: Personalizing Grasping Agents with Single Human-Robot Interaction</papertitle>
                <br>
                <a href="https://jhkim-snu.github.io/">Junghyun Kim</a>, <a href="https://gicheonkang.com/">Gi-Cheon Kang</a>, Jaein Kim, Seoyun Yang,  <strong>Minjoon Jung</strong>,
                <a href="https://bi.snu.ac.kr/~btzhang/">Byoung-Tak Zhang*</a>
                <br>
                <em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2024 <font color="red"><strong>(Oral)</strong></font>
                <br>
                <!--        <a href="https://github.com/minjoong507/BM-DETR">code</a>-->

                <a href="https://arxiv.org/abs/2310.12547">paper</a> /
                <a href="https://github.com/JHKim-snu/PGA">code</a>
                <p></p>
                <p>
                </p>
            </td>
        </tr>


        <tr onmouseout="merf_stop()" onmouseover="merf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <!--          <div class="two" id='merf_image'><video  width=100% height=100% muted autoplay loop>-->
                    <!--          <source src="images/merf_after.mp4" type="video/mp4">-->
                    <!--          Your browser does not support the video tag.-->
                    <!--          </video></div>-->
                    <img src='images/MPGN.jpg' width="160" height="160">
                </div>
                <script type="text/javascript">
                    function merf_start() {
                        document.getElementById('merf_image').style.opacity = "1";
                    }

                    function merf_stop() {
                        document.getElementById('merf_image').style.opacity = "0";
                    }
                    merf_stop()
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Modal-specific Pseudo Query Generation for Video Corpus Moment Retrieval</papertitle>
                <br>
                <strong>Minjoon Jung</strong>,
                Seongho Choi,
                Joochan Kim,
                <a href="http://wityworks.com/">Jin-Hwa Kim*</a>,
                <a href="https://bi.snu.ac.kr/~btzhang/">Byoung-Tak Zhang*</a>
                <br>
                <em>Empirical Methods in Natural Language Processing (EMNLP)</em>, 2022
                <br>
                <!--        <a href="https://aclanthology.org/2022.emnlp-main.530/">EMNLP</a>-->
                <!--        /-->
                <a href="https://arxiv.org/abs/2210.12617">paper</a> /
                <a href="https://github.com/minjoong507/MPGN">code</a>

                <p></p>
                <p>
                    <!--        We proposesd a self-supervised learning framework called Modal-specific Pseudo Query Generation Network (MPGN) for video corpus moment retrieval (VCMR).-->
                </p>
            </td>
        </tr>


        <tr onmouseout="eclipse_stop()" onmouseover="eclipse_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <!--          <div class="two" id='eclipse_image'><video  width=100% height=100% muted autoplay loop>-->
                    <!--          <source src="images/eclipse_after.mp4" type="video/mp4">-->
                    <!--          Your browser does not support the video tag.-->
                    <!--          </video></div>-->
                    <img src='images/stagemix.PNG' width="160" height="130">
                </div>
                <script type="text/javascript">
                    function eclipse_start() {
                        document.getElementById('eclipse_image').style.opacity = "1";
                    }

                    function eclipse_stop() {
                        document.getElementById('eclipse_image').style.opacity = "0";
                    }
                    eclipse_stop()
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Stagemix video generation using face and body keypoints detection</papertitle>
                <br>
                <strong>Minjoon Jung</strong>,
                <a href="https://lsh3163.github.io/seunghyunlee/">Seung-Hyun Lee</a>,
                Eunseon Sim,
                Minho Jo,
                Yujin Lee,
                Hyebin Choi,
                <br>
                <a href="https://sites.google.com/view/cau-cvml/cvmlcau/junseokkwon?authuser=0">Junseok Kwon*</a>
                <br>
                <em> Multimedia Tools and Applications</em>, 2022
                <br>
                <a href="https://link.springer.com/article/10.1007/s11042-022-13103-8">paper</a> /
                <a href="https://github.com/datamarket-tobigs/Cross-Cutting">code</a>
                <p></p>
                <p>
                    <!--        Shadows cast by unobserved occluders provide a high-frequency cue for recovering illumination and materials.-->
                </p>
            </td>
        </tr>

        <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()" >
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <!--          <div class="two" id='zipnerf_image'><video  width=100% height=100% muted autoplay loop>-->
                    <!--          <source src="images/zipnerf.mp4" type="video/mp4">-->
                    <!--          Your browser does not support the video tag.-->
                    <!--          </video></div>-->
                    <img src='images/vtt.png' width="160" height="130">
                </div>
                <script type="text/javascript">
                    function zipnerf_start() {
                        document.getElementById('zipnerf_image').style.opacity = "1";
                    }

                    function zipnerf_stop() {
                        document.getElementById('zipnerf_image').style.opacity = "0";
                    }
                    zipnerf_stop()
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Toward a Human-Level Video Understanding Intelligence</papertitle>
                <br>
                Yu-Jung Heo,
                Minsu Lee,
                Seongho Choi,
                Woo Suk Choi,
                Minjung Shin,
                <strong>Minjoon Jung</strong>,
                <br>
                Jeh-Kwang Ryu,
                <a href="https://bi.snu.ac.kr/~btzhang/">Byoung-Tak Zhang*</a>
                <br>
                <em>AAAI 2021 Fall Symposium Series on Artificial Intelligence for Human-Robot Interaction</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/2110.04203">paper</a> /
                <a>code</a>
                <p></p>
                <p>
                    <!--        Combining mip-NeRF 360 and grid-based models like Instant NGP lets us reduce error rates by 8%&ndash;77% and accelerate training by 24x.-->
                </p>
            </td>
        </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Service</heading>
                <ul>
                    <li>Conference Reviewer: EMNLP 2022, ACL 2023, EMNLP 2023</li>
                </ul>
                <p>
            </td>
        </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <p align="center">
            <a href="https://clustrmaps.com/site/1bxs5"  title="Visit tracker">
                <img src="//www.clustrmaps.com/map_v2.png?d=FtUdLRtU5_IUma_g6SQ6pfZabTo-l09PRKkLe52CeyU&cl=ffffff"></a>
        </p>
        <tr>
            <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                    <a href="https://minjoong507.github.io/">Minjoon Jung</a>. <a href="https://bi.snu.ac.kr/">BI LAB</a>, <a href="https://en.snu.ac.kr/">Seoul National University</a>
                </p>
            </td>
        </tr>
        </tbody></table>
    </td>
</tr>
</table>
</body>

</html>
